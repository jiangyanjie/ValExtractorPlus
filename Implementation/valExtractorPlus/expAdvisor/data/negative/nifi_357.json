{
    "id": 357,
    "expression": "session.getProvenanceReporter()",
    "projectName": "nifi",
    "commitID": "3fb445437580bf47f1bec2b553aaff5424eb9eef",
    "filePath": "nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutDatabaseRecord.java",
    "occurrences": 1,
    "isArithmeticExpression": 1,
    "isGetTypeMethod": 1,
    "expressionList": [
        {
            "nodeContext": "session.getProvenanceReporter()",
            "nodeType": "MethodInvocation",
            "nodePosition": {
                "charLength": 31,
                "startLineNumber": 729,
                "startColumnNumber": 12,
                "endLineNumber": 729,
                "endColumnNumber": 43
            },
            "astNodeNumber": 3,
            "astHeight": 2,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 71,
                        "startLineNumber": 729,
                        "startColumnNumber": 12,
                        "endLineNumber": 729,
                        "endColumnNumber": 83
                    },
                    "nodeContext": "session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 9,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 72,
                        "startLineNumber": 729,
                        "startColumnNumber": 12,
                        "endLineNumber": 729,
                        "endColumnNumber": 84
                    },
                    "nodeContext": "session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 10,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.TryStatement,body]",
                    "nodePosition": {
                        "charLength": 3242,
                        "startLineNumber": 669,
                        "startColumnNumber": 78,
                        "endLineNumber": 731,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final int queryTimeout=functionContext.queryTimeout;\n  try {\n    ps.setQueryTimeout(queryTimeout);\n  }\n catch (  SQLException se) {\n    if (queryTimeout > 0) {\n      throw se;\n    }\n  }\n  Record currentRecord;\n  List<Integer> fieldIndexes=sqlHolder.getFieldIndexes();\n  final Integer maxBatchSize=context.getProperty(MAX_BATCH_SIZE).evaluateAttributeExpressions(flowFile).asInteger();\n  int currentBatchSize=0;\n  int batchIndex=0;\n  while ((currentRecord=recordParser.nextRecord()) != null) {\n    Object[] values=currentRecord.getValues();\n    if (values != null) {\n      if (fieldIndexes != null) {\n        for (int i=0; i < fieldIndexes.size(); i++) {\n          if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n            ps.setObject(i * 2 + 1,values[fieldIndexes.get(i)]);\n            ps.setObject(i * 2 + 2,values[fieldIndexes.get(i)]);\n          }\n else {\n            ps.setObject(i + 1,values[fieldIndexes.get(i)]);\n          }\n        }\n      }\n else {\n        for (int i=0; i < values.length; i++) {\n          if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n            ps.setObject(i * 2 + 1,values[i]);\n            ps.setObject(i * 2 + 2,values[i]);\n          }\n else {\n            ps.setObject(i + 1,values[i]);\n          }\n        }\n      }\n      ps.addBatch();\n      if (++currentBatchSize == maxBatchSize) {\n        batchIndex++;\n        log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n        ps.executeBatch();\n        currentBatchSize=0;\n      }\n    }\n  }\n  if (currentBatchSize > 0) {\n    batchIndex++;\n    log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n    ps.executeBatch();\n  }\n  result.routeTo(flowFile,REL_SUCCESS);\n  session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 307,
                    "astHeight": 16
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3312,
                        "startLineNumber": 669,
                        "startColumnNumber": 8,
                        "endLineNumber": 731,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "try (PreparedStatement ps=con.prepareStatement(sqlHolder.getSql())){\n  final int queryTimeout=functionContext.queryTimeout;\n  try {\n    ps.setQueryTimeout(queryTimeout);\n  }\n catch (  SQLException se) {\n    if (queryTimeout > 0) {\n      throw se;\n    }\n  }\n  Record currentRecord;\n  List<Integer> fieldIndexes=sqlHolder.getFieldIndexes();\n  final Integer maxBatchSize=context.getProperty(MAX_BATCH_SIZE).evaluateAttributeExpressions(flowFile).asInteger();\n  int currentBatchSize=0;\n  int batchIndex=0;\n  while ((currentRecord=recordParser.nextRecord()) != null) {\n    Object[] values=currentRecord.getValues();\n    if (values != null) {\n      if (fieldIndexes != null) {\n        for (int i=0; i < fieldIndexes.size(); i++) {\n          if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n            ps.setObject(i * 2 + 1,values[fieldIndexes.get(i)]);\n            ps.setObject(i * 2 + 2,values[fieldIndexes.get(i)]);\n          }\n else {\n            ps.setObject(i + 1,values[fieldIndexes.get(i)]);\n          }\n        }\n      }\n else {\n        for (int i=0; i < values.length; i++) {\n          if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n            ps.setObject(i * 2 + 1,values[i]);\n            ps.setObject(i * 2 + 2,values[i]);\n          }\n else {\n            ps.setObject(i + 1,values[i]);\n          }\n        }\n      }\n      ps.addBatch();\n      if (++currentBatchSize == maxBatchSize) {\n        batchIndex++;\n        log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n        ps.executeBatch();\n        currentBatchSize=0;\n      }\n    }\n  }\n  if (currentBatchSize > 0) {\n    batchIndex++;\n    log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n    ps.executeBatch();\n  }\n  result.routeTo(flowFile,REL_SUCCESS);\n  session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n}\n ",
                    "nodeType": "TryStatement",
                    "astNodeNumber": 319,
                    "astHeight": 17
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 6317,
                        "startLineNumber": 609,
                        "startColumnNumber": 97,
                        "endLineNumber": 732,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  final RecordSchema recordSchema=recordParser.getSchema();\n  final ComponentLog log=getLogger();\n  final String catalog=context.getProperty(CATALOG_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String schemaName=context.getProperty(SCHEMA_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String tableName=context.getProperty(TABLE_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String updateKeys=context.getProperty(UPDATE_KEYS).evaluateAttributeExpressions(flowFile).getValue();\n  final SchemaKey schemaKey=new PutDatabaseRecord.SchemaKey(catalog,schemaName,tableName);\n  if (StringUtils.isEmpty(tableName)) {\n    throw new IllegalArgumentException(format(\"Cannot process %s because Table Name is null or empty\",flowFile));\n  }\n  final boolean includePrimaryKeys=updateKeys == null;\n  TableSchema tableSchema=schemaCache.get(schemaKey,key -> {\n    try {\n      return TableSchema.from(con,catalog,schemaName,tableName,settings.translateFieldNames,includePrimaryKeys);\n    }\n catch (    SQLException e) {\n      throw new ProcessException(e);\n    }\n  }\n);\n  if (tableSchema == null) {\n    throw new IllegalArgumentException(\"No table schema specified!\");\n  }\n  final StringBuilder tableNameBuilder=new StringBuilder();\n  if (catalog != null) {\n    tableNameBuilder.append(catalog).append(\".\");\n  }\n  if (schemaName != null) {\n    tableNameBuilder.append(schemaName).append(\".\");\n  }\n  tableNameBuilder.append(tableName);\n  final String fqTableName=tableNameBuilder.toString();\n  if (recordSchema == null) {\n    throw new IllegalArgumentException(\"No record schema specified!\");\n  }\n  final SqlAndIncludedColumns sqlHolder;\n  if (INSERT_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateInsert(recordSchema,fqTableName,tableSchema,settings);\n  }\n else   if (UPDATE_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateUpdate(recordSchema,fqTableName,updateKeys,tableSchema,settings);\n  }\n else   if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateDelete(recordSchema,fqTableName,tableSchema,settings);\n  }\n else {\n    throw new IllegalArgumentException(format(\"Statement Type %s is not valid, FlowFile %s\",statementType,flowFile));\n  }\n  try (PreparedStatement ps=con.prepareStatement(sqlHolder.getSql())){\n    final int queryTimeout=functionContext.queryTimeout;\n    try {\n      ps.setQueryTimeout(queryTimeout);\n    }\n catch (    SQLException se) {\n      if (queryTimeout > 0) {\n        throw se;\n      }\n    }\n    Record currentRecord;\n    List<Integer> fieldIndexes=sqlHolder.getFieldIndexes();\n    final Integer maxBatchSize=context.getProperty(MAX_BATCH_SIZE).evaluateAttributeExpressions(flowFile).asInteger();\n    int currentBatchSize=0;\n    int batchIndex=0;\n    while ((currentRecord=recordParser.nextRecord()) != null) {\n      Object[] values=currentRecord.getValues();\n      if (values != null) {\n        if (fieldIndexes != null) {\n          for (int i=0; i < fieldIndexes.size(); i++) {\n            if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n              ps.setObject(i * 2 + 1,values[fieldIndexes.get(i)]);\n              ps.setObject(i * 2 + 2,values[fieldIndexes.get(i)]);\n            }\n else {\n              ps.setObject(i + 1,values[fieldIndexes.get(i)]);\n            }\n          }\n        }\n else {\n          for (int i=0; i < values.length; i++) {\n            if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n              ps.setObject(i * 2 + 1,values[i]);\n              ps.setObject(i * 2 + 2,values[i]);\n            }\n else {\n              ps.setObject(i + 1,values[i]);\n            }\n          }\n        }\n        ps.addBatch();\n        if (++currentBatchSize == maxBatchSize) {\n          batchIndex++;\n          log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n          ps.executeBatch();\n          currentBatchSize=0;\n        }\n      }\n    }\n    if (currentBatchSize > 0) {\n      batchIndex++;\n      log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n      ps.executeBatch();\n    }\n    result.routeTo(flowFile,REL_SUCCESS);\n    session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n  }\n }\n",
                    "nodeType": "Block",
                    "astNodeNumber": 602,
                    "astHeight": 18
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 6703,
                        "startLineNumber": 606,
                        "startColumnNumber": 4,
                        "endLineNumber": 732,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void executeDML(ProcessContext context,ProcessSession session,FlowFile flowFile,FunctionContext functionContext,RoutingResult result,Connection con,RecordReader recordParser,String statementType,DMLSettings settings) throws IllegalArgumentException, MalformedRecordException, IOException, SQLException {\n  final RecordSchema recordSchema=recordParser.getSchema();\n  final ComponentLog log=getLogger();\n  final String catalog=context.getProperty(CATALOG_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String schemaName=context.getProperty(SCHEMA_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String tableName=context.getProperty(TABLE_NAME).evaluateAttributeExpressions(flowFile).getValue();\n  final String updateKeys=context.getProperty(UPDATE_KEYS).evaluateAttributeExpressions(flowFile).getValue();\n  final SchemaKey schemaKey=new PutDatabaseRecord.SchemaKey(catalog,schemaName,tableName);\n  if (StringUtils.isEmpty(tableName)) {\n    throw new IllegalArgumentException(format(\"Cannot process %s because Table Name is null or empty\",flowFile));\n  }\n  final boolean includePrimaryKeys=updateKeys == null;\n  TableSchema tableSchema=schemaCache.get(schemaKey,key -> {\n    try {\n      return TableSchema.from(con,catalog,schemaName,tableName,settings.translateFieldNames,includePrimaryKeys);\n    }\n catch (    SQLException e) {\n      throw new ProcessException(e);\n    }\n  }\n);\n  if (tableSchema == null) {\n    throw new IllegalArgumentException(\"No table schema specified!\");\n  }\n  final StringBuilder tableNameBuilder=new StringBuilder();\n  if (catalog != null) {\n    tableNameBuilder.append(catalog).append(\".\");\n  }\n  if (schemaName != null) {\n    tableNameBuilder.append(schemaName).append(\".\");\n  }\n  tableNameBuilder.append(tableName);\n  final String fqTableName=tableNameBuilder.toString();\n  if (recordSchema == null) {\n    throw new IllegalArgumentException(\"No record schema specified!\");\n  }\n  final SqlAndIncludedColumns sqlHolder;\n  if (INSERT_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateInsert(recordSchema,fqTableName,tableSchema,settings);\n  }\n else   if (UPDATE_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateUpdate(recordSchema,fqTableName,updateKeys,tableSchema,settings);\n  }\n else   if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n    sqlHolder=generateDelete(recordSchema,fqTableName,tableSchema,settings);\n  }\n else {\n    throw new IllegalArgumentException(format(\"Statement Type %s is not valid, FlowFile %s\",statementType,flowFile));\n  }\n  try (PreparedStatement ps=con.prepareStatement(sqlHolder.getSql())){\n    final int queryTimeout=functionContext.queryTimeout;\n    try {\n      ps.setQueryTimeout(queryTimeout);\n    }\n catch (    SQLException se) {\n      if (queryTimeout > 0) {\n        throw se;\n      }\n    }\n    Record currentRecord;\n    List<Integer> fieldIndexes=sqlHolder.getFieldIndexes();\n    final Integer maxBatchSize=context.getProperty(MAX_BATCH_SIZE).evaluateAttributeExpressions(flowFile).asInteger();\n    int currentBatchSize=0;\n    int batchIndex=0;\n    while ((currentRecord=recordParser.nextRecord()) != null) {\n      Object[] values=currentRecord.getValues();\n      if (values != null) {\n        if (fieldIndexes != null) {\n          for (int i=0; i < fieldIndexes.size(); i++) {\n            if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n              ps.setObject(i * 2 + 1,values[fieldIndexes.get(i)]);\n              ps.setObject(i * 2 + 2,values[fieldIndexes.get(i)]);\n            }\n else {\n              ps.setObject(i + 1,values[fieldIndexes.get(i)]);\n            }\n          }\n        }\n else {\n          for (int i=0; i < values.length; i++) {\n            if (DELETE_TYPE.equalsIgnoreCase(statementType)) {\n              ps.setObject(i * 2 + 1,values[i]);\n              ps.setObject(i * 2 + 2,values[i]);\n            }\n else {\n              ps.setObject(i + 1,values[i]);\n            }\n          }\n        }\n        ps.addBatch();\n        if (++currentBatchSize == maxBatchSize) {\n          batchIndex++;\n          log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n          ps.executeBatch();\n          currentBatchSize=0;\n        }\n      }\n    }\n    if (currentBatchSize > 0) {\n      batchIndex++;\n      log.debug(\"Executing query {}; fieldIndexes: {}; batch index: {}; batch size: {}\",new Object[]{sqlHolder.getSql(),sqlHolder.getFieldIndexes(),batchIndex,currentBatchSize});\n      ps.executeBatch();\n    }\n    result.routeTo(flowFile,REL_SUCCESS);\n    session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n  }\n }\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 650,
                    "astHeight": 19
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 72,
                    "startLineNumber": 729,
                    "startColumnNumber": 12,
                    "endLineNumber": 729,
                    "endColumnNumber": 84
                },
                "nodeContext": "session.getProvenanceReporter().send(flowFile,functionContext.jdbcUrl);\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 10,
                "astHeight": 4
            },
            "tokenLength": 2,
            "type": "org.apache.nifi.provenance.ProvenanceReporter"
        }
    ],
    "positionList": [
        {
            "charLength": 31,
            "startLineNumber": 729,
            "startColumnNumber": 12,
            "endLineNumber": 729,
            "endColumnNumber": 43
        }
    ],
    "layoutRelationDataList": []
}