{
    "id": 36,
    "expression": "flowFile",
    "projectName": "nifi",
    "commitID": "84b2484fd46a0fc883e8b9d380ccef199432db35",
    "filePath": "nifi-nar-bundles/nifi-framework-bundle/nifi-framework/nifi-framework-components/src/main/java/org/apache/nifi/controller/repository/StandardProcessSession.java",
    "occurrences": 26,
    "isArithmeticExpression": 1,
    "isGetTypeMethod": 1,
    "expressionList": [
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1316,
                "startColumnNumber": 45,
                "endLineNumber": 1316,
                "endColumnNumber": 53
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                    "nodePosition": {
                        "charLength": 38,
                        "startLineNumber": 1316,
                        "startColumnNumber": 16,
                        "endLineNumber": 1316,
                        "endColumnNumber": 54
                    },
                    "nodeContext": "openInputStreams.containsKey(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 314,
                        "startLineNumber": 1316,
                        "startColumnNumber": 12,
                        "endLineNumber": 1319,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (openInputStreams.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                "nodePosition": {
                    "charLength": 38,
                    "startLineNumber": 1316,
                    "startColumnNumber": 16,
                    "endLineNumber": 1316,
                    "endColumnNumber": 54
                },
                "nodeContext": "openInputStreams.containsKey(flowFile)",
                "nodeType": "MethodInvocation",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1317,
                "startColumnNumber": 48,
                "endLineNumber": 1317,
                "endColumnNumber": 56
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                    "nodePosition": {
                        "charLength": 204,
                        "startLineNumber": 1317,
                        "startColumnNumber": 48,
                        "endLineNumber": 1318,
                        "endColumnNumber": 114
                    },
                    "nodeContext": "flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\"",
                    "nodeType": "InfixExpression",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ThrowStatement,expression]",
                    "nodePosition": {
                        "charLength": 231,
                        "startLineNumber": 1317,
                        "startColumnNumber": 22,
                        "endLineNumber": 1318,
                        "endColumnNumber": 115
                    },
                    "nodeContext": "new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\")",
                    "nodeType": "ClassInstanceCreation",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 238,
                        "startLineNumber": 1317,
                        "startColumnNumber": 16,
                        "endLineNumber": 1318,
                        "endColumnNumber": 116
                    },
                    "nodeContext": "throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n",
                    "nodeType": "ThrowStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 270,
                        "startLineNumber": 1316,
                        "startColumnNumber": 56,
                        "endLineNumber": 1319,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 9,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 314,
                        "startLineNumber": 1316,
                        "startColumnNumber": 12,
                        "endLineNumber": 1319,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (openInputStreams.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                "nodePosition": {
                    "charLength": 204,
                    "startLineNumber": 1317,
                    "startColumnNumber": 48,
                    "endLineNumber": 1318,
                    "endColumnNumber": 114
                },
                "nodeContext": "flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\"",
                "nodeType": "InfixExpression",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1321,
                "startColumnNumber": 46,
                "endLineNumber": 1321,
                "endColumnNumber": 54
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                    "nodePosition": {
                        "charLength": 39,
                        "startLineNumber": 1321,
                        "startColumnNumber": 16,
                        "endLineNumber": 1321,
                        "endColumnNumber": 55
                    },
                    "nodeContext": "openOutputStreams.containsKey(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 317,
                        "startLineNumber": 1321,
                        "startColumnNumber": 12,
                        "endLineNumber": 1324,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (openOutputStreams.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                "nodePosition": {
                    "charLength": 39,
                    "startLineNumber": 1321,
                    "startColumnNumber": 16,
                    "endLineNumber": 1321,
                    "endColumnNumber": 55
                },
                "nodeContext": "openOutputStreams.containsKey(flowFile)",
                "nodeType": "MethodInvocation",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1322,
                "startColumnNumber": 48,
                "endLineNumber": 1322,
                "endColumnNumber": 56
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                    "nodePosition": {
                        "charLength": 206,
                        "startLineNumber": 1322,
                        "startColumnNumber": 48,
                        "endLineNumber": 1323,
                        "endColumnNumber": 116
                    },
                    "nodeContext": "flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\"",
                    "nodeType": "InfixExpression",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ThrowStatement,expression]",
                    "nodePosition": {
                        "charLength": 233,
                        "startLineNumber": 1322,
                        "startColumnNumber": 22,
                        "endLineNumber": 1323,
                        "endColumnNumber": 117
                    },
                    "nodeContext": "new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\")",
                    "nodeType": "ClassInstanceCreation",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 240,
                        "startLineNumber": 1322,
                        "startColumnNumber": 16,
                        "endLineNumber": 1323,
                        "endColumnNumber": 118
                    },
                    "nodeContext": "throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n",
                    "nodeType": "ThrowStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 272,
                        "startLineNumber": 1321,
                        "startColumnNumber": 57,
                        "endLineNumber": 1324,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 9,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 317,
                        "startLineNumber": 1321,
                        "startColumnNumber": 12,
                        "endLineNumber": 1324,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (openOutputStreams.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                "nodePosition": {
                    "charLength": 206,
                    "startLineNumber": 1322,
                    "startColumnNumber": 48,
                    "endLineNumber": 1323,
                    "endColumnNumber": 116
                },
                "nodeContext": "flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\"",
                "nodeType": "InfixExpression",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1326,
                "startColumnNumber": 45,
                "endLineNumber": 1326,
                "endColumnNumber": 53
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                    "nodePosition": {
                        "charLength": 38,
                        "startLineNumber": 1326,
                        "startColumnNumber": 16,
                        "endLineNumber": 1326,
                        "endColumnNumber": 54
                    },
                    "nodeContext": "readRecursionSet.containsKey(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 237,
                        "startLineNumber": 1326,
                        "startColumnNumber": 12,
                        "endLineNumber": 1328,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (readRecursionSet.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                "nodePosition": {
                    "charLength": 38,
                    "startLineNumber": 1326,
                    "startColumnNumber": 16,
                    "endLineNumber": 1326,
                    "endColumnNumber": 54
                },
                "nodeContext": "readRecursionSet.containsKey(flowFile)",
                "nodeType": "MethodInvocation",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1327,
                "startColumnNumber": 48,
                "endLineNumber": 1327,
                "endColumnNumber": 56
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                    "nodePosition": {
                        "charLength": 127,
                        "startLineNumber": 1327,
                        "startColumnNumber": 48,
                        "endLineNumber": 1327,
                        "endColumnNumber": 175
                    },
                    "nodeContext": "flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\"",
                    "nodeType": "InfixExpression",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ThrowStatement,expression]",
                    "nodePosition": {
                        "charLength": 154,
                        "startLineNumber": 1327,
                        "startColumnNumber": 22,
                        "endLineNumber": 1327,
                        "endColumnNumber": 176
                    },
                    "nodeContext": "new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\")",
                    "nodeType": "ClassInstanceCreation",
                    "astNodeNumber": 6,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 161,
                        "startLineNumber": 1327,
                        "startColumnNumber": 16,
                        "endLineNumber": 1327,
                        "endColumnNumber": 177
                    },
                    "nodeContext": "throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n",
                    "nodeType": "ThrowStatement",
                    "astNodeNumber": 7,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 193,
                        "startLineNumber": 1326,
                        "startColumnNumber": 56,
                        "endLineNumber": 1328,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 8,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 237,
                        "startLineNumber": 1326,
                        "startColumnNumber": 12,
                        "endLineNumber": 1328,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (readRecursionSet.containsKey(flowFile)) {\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 161,
                    "startLineNumber": 1327,
                    "startColumnNumber": 16,
                    "endLineNumber": 1327,
                    "endColumnNumber": 177
                },
                "nodeContext": "throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n",
                "nodeType": "ThrowStatement",
                "astNodeNumber": 7,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1329,
                "startColumnNumber": 43,
                "endLineNumber": 1329,
                "endColumnNumber": 51
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                    "nodePosition": {
                        "charLength": 36,
                        "startLineNumber": 1329,
                        "startColumnNumber": 16,
                        "endLineNumber": 1329,
                        "endColumnNumber": 52
                    },
                    "nodeContext": "writeRecursionSet.contains(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 237,
                        "startLineNumber": 1329,
                        "startColumnNumber": 12,
                        "endLineNumber": 1331,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (writeRecursionSet.contains(flowFile)) {\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,expression]",
                "nodePosition": {
                    "charLength": 36,
                    "startLineNumber": 1329,
                    "startColumnNumber": 16,
                    "endLineNumber": 1329,
                    "endColumnNumber": 52
                },
                "nodeContext": "writeRecursionSet.contains(flowFile)",
                "nodeType": "MethodInvocation",
                "astNodeNumber": 4,
                "astHeight": 2
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1330,
                "startColumnNumber": 48,
                "endLineNumber": 1330,
                "endColumnNumber": 56
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                    "nodePosition": {
                        "charLength": 129,
                        "startLineNumber": 1330,
                        "startColumnNumber": 48,
                        "endLineNumber": 1330,
                        "endColumnNumber": 177
                    },
                    "nodeContext": "flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\"",
                    "nodeType": "InfixExpression",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ThrowStatement,expression]",
                    "nodePosition": {
                        "charLength": 156,
                        "startLineNumber": 1330,
                        "startColumnNumber": 22,
                        "endLineNumber": 1330,
                        "endColumnNumber": 178
                    },
                    "nodeContext": "new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\")",
                    "nodeType": "ClassInstanceCreation",
                    "astNodeNumber": 6,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 163,
                        "startLineNumber": 1330,
                        "startColumnNumber": 16,
                        "endLineNumber": 1330,
                        "endColumnNumber": 179
                    },
                    "nodeContext": "throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n",
                    "nodeType": "ThrowStatement",
                    "astNodeNumber": 7,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 195,
                        "startLineNumber": 1329,
                        "startColumnNumber": 54,
                        "endLineNumber": 1331,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 8,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 237,
                        "startLineNumber": 1329,
                        "startColumnNumber": 12,
                        "endLineNumber": 1331,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (writeRecursionSet.contains(flowFile)) {\n  throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 163,
                    "startLineNumber": 1330,
                    "startColumnNumber": 16,
                    "endLineNumber": 1330,
                    "endColumnNumber": 179
                },
                "nodeContext": "throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n",
                "nodeType": "ThrowStatement",
                "astNodeNumber": 7,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1333,
                "startColumnNumber": 62,
                "endLineNumber": 1333,
                "endColumnNumber": 70
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 19,
                        "startLineNumber": 1333,
                        "startColumnNumber": 52,
                        "endLineNumber": 1333,
                        "endColumnNumber": 71
                    },
                    "nodeContext": "getRecord(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 28,
                        "startLineNumber": 1333,
                        "startColumnNumber": 43,
                        "endLineNumber": 1333,
                        "endColumnNumber": 71
                    },
                    "nodeContext": "record=getRecord(flowFile)",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 5,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 60,
                        "startLineNumber": 1333,
                        "startColumnNumber": 12,
                        "endLineNumber": 1333,
                        "endColumnNumber": 72
                    },
                    "nodeContext": "final StandardRepositoryRecord record=getRecord(flowFile);\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 9,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 60,
                    "startLineNumber": 1333,
                    "startColumnNumber": 12,
                    "endLineNumber": 1333,
                    "endColumnNumber": 72
                },
                "nodeContext": "final StandardRepositoryRecord record=getRecord(flowFile);\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 9,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1335,
                "startColumnNumber": 52,
                "endLineNumber": 1335,
                "endColumnNumber": 60
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
                    "nodePosition": {
                        "charLength": 63,
                        "startLineNumber": 1335,
                        "startColumnNumber": 52,
                        "endLineNumber": 1335,
                        "endColumnNumber": 115
                    },
                    "nodeContext": "flowFile + \" is not known in this session (\" + toString()+ \")\"",
                    "nodeType": "InfixExpression",
                    "astNodeNumber": 6,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ThrowStatement,expression]",
                    "nodePosition": {
                        "charLength": 94,
                        "startLineNumber": 1335,
                        "startColumnNumber": 22,
                        "endLineNumber": 1335,
                        "endColumnNumber": 116
                    },
                    "nodeContext": "new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\")",
                    "nodeType": "ClassInstanceCreation",
                    "astNodeNumber": 9,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 101,
                        "startLineNumber": 1335,
                        "startColumnNumber": 16,
                        "endLineNumber": 1335,
                        "endColumnNumber": 117
                    },
                    "nodeContext": "throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n",
                    "nodeType": "ThrowStatement",
                    "astNodeNumber": 10,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 133,
                        "startLineNumber": 1334,
                        "startColumnNumber": 32,
                        "endLineNumber": 1336,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 11,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 153,
                        "startLineNumber": 1334,
                        "startColumnNumber": 12,
                        "endLineNumber": 1336,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (record == null) {\n  throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 15,
                    "astHeight": 7
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1410,
                        "startLineNumber": 1315,
                        "startColumnNumber": 50,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 79,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1452,
                        "startLineNumber": 1315,
                        "startColumnNumber": 8,
                        "endLineNumber": 1337,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  if (openInputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n  }\n  if (openOutputStreams.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n  }\n  if (readRecursionSet.containsKey(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n  }\n  if (writeRecursionSet.contains(flowFile)) {\n    throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n  }\n  final StandardRepositoryRecord record=getRecord(flowFile);\n  if (record == null) {\n    throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 86,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 101,
                    "startLineNumber": 1335,
                    "startColumnNumber": 16,
                    "endLineNumber": 1335,
                    "endColumnNumber": 117
                },
                "nodeContext": "throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n",
                "nodeType": "ThrowStatement",
                "astNodeNumber": 10,
                "astHeight": 5
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1384,
                "startColumnNumber": 42,
                "endLineNumber": 1384,
                "endColumnNumber": 50
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 48,
                        "startLineNumber": 1384,
                        "startColumnNumber": 42,
                        "endLineNumber": 1384,
                        "endColumnNumber": 90
                    },
                    "nodeContext": "flowFile.getAttribute(CoreAttributes.UUID.key())",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 61,
                        "startLineNumber": 1384,
                        "startColumnNumber": 29,
                        "endLineNumber": 1384,
                        "endColumnNumber": 90
                    },
                    "nodeContext": "flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key())",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 10,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 75,
                        "startLineNumber": 1384,
                        "startColumnNumber": 16,
                        "endLineNumber": 1384,
                        "endColumnNumber": 91
                    },
                    "nodeContext": "final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 475,
                        "startLineNumber": 1383,
                        "startColumnNumber": 54,
                        "endLineNumber": 1394,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (childrenIds.contains(flowFileId)) {\n    eventBuilder.removeChildFlowFile(flowFile);\n    if (copy == null) {\n      copy=eventBuilder.copy();\n      copy.getChildFlowFileIds().clear();\n    }\n    copy.addChildFlowFile(flowFileId);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 48,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 517,
                        "startLineNumber": 1383,
                        "startColumnNumber": 12,
                        "endLineNumber": 1394,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (childrenIds.contains(flowFileId)) {\n    eventBuilder.removeChildFlowFile(flowFile);\n    if (copy == null) {\n      copy=eventBuilder.copy();\n      copy.getChildFlowFileIds().clear();\n    }\n    copy.addChildFlowFile(flowFileId);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 55,
                    "astHeight": 10
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1227,
                        "startLineNumber": 1371,
                        "startColumnNumber": 101,
                        "endLineNumber": 1400,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFile eventFlowFile=entry.getKey();\n  final ProvenanceEventBuilder eventBuilder=entry.getValue();\n  if (!flowFiles.contains(eventFlowFile)) {\n    continue;\n  }\n  final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n  ProvenanceEventBuilder copy=null;\n  for (  final FlowFile flowFile : flowFiles) {\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (childrenIds.contains(flowFileId)) {\n      eventBuilder.removeChildFlowFile(flowFile);\n      if (copy == null) {\n        copy=eventBuilder.copy();\n        copy.getChildFlowFileIds().clear();\n      }\n      copy.addChildFlowFile(flowFileId);\n    }\n  }\n  if (copy != null) {\n    newOwner.forkEventBuilders.put(eventFlowFile,copy);\n    forkedFlowFilesMigrated.add(eventFlowFile);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 122,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1320,
                        "startLineNumber": 1371,
                        "startColumnNumber": 8,
                        "endLineNumber": 1400,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n  final FlowFile eventFlowFile=entry.getKey();\n  final ProvenanceEventBuilder eventBuilder=entry.getValue();\n  if (!flowFiles.contains(eventFlowFile)) {\n    continue;\n  }\n  final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n  ProvenanceEventBuilder copy=null;\n  for (  final FlowFile flowFile : flowFiles) {\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (childrenIds.contains(flowFileId)) {\n      eventBuilder.removeChildFlowFile(flowFile);\n      if (copy == null) {\n        copy=eventBuilder.copy();\n        copy.getChildFlowFileIds().clear();\n      }\n      copy.addChildFlowFile(flowFileId);\n    }\n  }\n  if (copy != null) {\n    newOwner.forkEventBuilders.put(eventFlowFile,copy);\n    forkedFlowFilesMigrated.add(eventFlowFile);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 138,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 75,
                    "startLineNumber": 1384,
                    "startColumnNumber": 16,
                    "endLineNumber": 1384,
                    "endColumnNumber": 91
                },
                "nodeContext": "final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 14,
                "astHeight": 6
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1386,
                "startColumnNumber": 53,
                "endLineNumber": 1386,
                "endColumnNumber": 61
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 42,
                        "startLineNumber": 1386,
                        "startColumnNumber": 20,
                        "endLineNumber": 1386,
                        "endColumnNumber": 62
                    },
                    "nodeContext": "eventBuilder.removeChildFlowFile(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 43,
                        "startLineNumber": 1386,
                        "startColumnNumber": 20,
                        "endLineNumber": 1386,
                        "endColumnNumber": 63
                    },
                    "nodeContext": "eventBuilder.removeChildFlowFile(flowFile);\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 5,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 313,
                        "startLineNumber": 1385,
                        "startColumnNumber": 54,
                        "endLineNumber": 1393,
                        "endColumnNumber": 17
                    },
                    "nodeContext": "{\n  eventBuilder.removeChildFlowFile(flowFile);\n  if (copy == null) {\n    copy=eventBuilder.copy();\n    copy.getChildFlowFileIds().clear();\n  }\n  copy.addChildFlowFile(flowFileId);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 28,
                    "astHeight": 7
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 351,
                        "startLineNumber": 1385,
                        "startColumnNumber": 16,
                        "endLineNumber": 1393,
                        "endColumnNumber": 17
                    },
                    "nodeContext": "if (childrenIds.contains(flowFileId)) {\n  eventBuilder.removeChildFlowFile(flowFile);\n  if (copy == null) {\n    copy=eventBuilder.copy();\n    copy.getChildFlowFileIds().clear();\n  }\n  copy.addChildFlowFile(flowFileId);\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 33,
                    "astHeight": 8
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 475,
                        "startLineNumber": 1383,
                        "startColumnNumber": 54,
                        "endLineNumber": 1394,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (childrenIds.contains(flowFileId)) {\n    eventBuilder.removeChildFlowFile(flowFile);\n    if (copy == null) {\n      copy=eventBuilder.copy();\n      copy.getChildFlowFileIds().clear();\n    }\n    copy.addChildFlowFile(flowFileId);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 48,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 517,
                        "startLineNumber": 1383,
                        "startColumnNumber": 12,
                        "endLineNumber": 1394,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (childrenIds.contains(flowFileId)) {\n    eventBuilder.removeChildFlowFile(flowFile);\n    if (copy == null) {\n      copy=eventBuilder.copy();\n      copy.getChildFlowFileIds().clear();\n    }\n    copy.addChildFlowFile(flowFileId);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 55,
                    "astHeight": 10
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 1227,
                        "startLineNumber": 1371,
                        "startColumnNumber": 101,
                        "endLineNumber": 1400,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFile eventFlowFile=entry.getKey();\n  final ProvenanceEventBuilder eventBuilder=entry.getValue();\n  if (!flowFiles.contains(eventFlowFile)) {\n    continue;\n  }\n  final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n  ProvenanceEventBuilder copy=null;\n  for (  final FlowFile flowFile : flowFiles) {\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (childrenIds.contains(flowFileId)) {\n      eventBuilder.removeChildFlowFile(flowFile);\n      if (copy == null) {\n        copy=eventBuilder.copy();\n        copy.getChildFlowFileIds().clear();\n      }\n      copy.addChildFlowFile(flowFileId);\n    }\n  }\n  if (copy != null) {\n    newOwner.forkEventBuilders.put(eventFlowFile,copy);\n    forkedFlowFilesMigrated.add(eventFlowFile);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 122,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1320,
                        "startLineNumber": 1371,
                        "startColumnNumber": 8,
                        "endLineNumber": 1400,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n  final FlowFile eventFlowFile=entry.getKey();\n  final ProvenanceEventBuilder eventBuilder=entry.getValue();\n  if (!flowFiles.contains(eventFlowFile)) {\n    continue;\n  }\n  final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n  ProvenanceEventBuilder copy=null;\n  for (  final FlowFile flowFile : flowFiles) {\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (childrenIds.contains(flowFileId)) {\n      eventBuilder.removeChildFlowFile(flowFile);\n      if (copy == null) {\n        copy=eventBuilder.copy();\n        copy.getChildFlowFileIds().clear();\n      }\n      copy.addChildFlowFile(flowFileId);\n    }\n  }\n  if (copy != null) {\n    newOwner.forkEventBuilders.put(eventFlowFile,copy);\n    forkedFlowFilesMigrated.add(eventFlowFile);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 138,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 43,
                    "startLineNumber": 1386,
                    "startColumnNumber": 20,
                    "endLineNumber": 1386,
                    "endColumnNumber": 63
                },
                "nodeContext": "eventBuilder.removeChildFlowFile(flowFile);\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 5,
                "astHeight": 3
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1407,
                "startColumnNumber": 67,
                "endLineNumber": 1407,
                "endColumnNumber": 75
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 25,
                        "startLineNumber": 1407,
                        "startColumnNumber": 50,
                        "endLineNumber": 1407,
                        "endColumnNumber": 75
                    },
                    "nodeContext": "(FlowFileRecord)flowFile",
                    "nodeType": "CastExpression",
                    "astNodeNumber": 4,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 42,
                        "startLineNumber": 1407,
                        "startColumnNumber": 33,
                        "endLineNumber": 1407,
                        "endColumnNumber": 75
                    },
                    "nodeContext": "flowFileRecord=(FlowFileRecord)flowFile",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 6,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 64,
                        "startLineNumber": 1407,
                        "startColumnNumber": 12,
                        "endLineNumber": 1407,
                        "endColumnNumber": 76
                    },
                    "nodeContext": "final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 10,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 64,
                    "startLineNumber": 1407,
                    "startColumnNumber": 12,
                    "endLineNumber": 1407,
                    "endColumnNumber": 76
                },
                "nodeContext": "final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 10,
                "astHeight": 5
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1409,
                "startColumnNumber": 76,
                "endLineNumber": 1409,
                "endColumnNumber": 84
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.MethodInvocation,arguments]",
                    "nodePosition": {
                        "charLength": 16,
                        "startLineNumber": 1409,
                        "startColumnNumber": 76,
                        "endLineNumber": 1409,
                        "endColumnNumber": 92
                    },
                    "nodeContext": "flowFile.getId()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 37,
                        "startLineNumber": 1409,
                        "startColumnNumber": 56,
                        "endLineNumber": 1409,
                        "endColumnNumber": 93
                    },
                    "nodeContext": "this.records.remove(flowFile.getId())",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 8,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 50,
                        "startLineNumber": 1409,
                        "startColumnNumber": 43,
                        "endLineNumber": 1409,
                        "endColumnNumber": 93
                    },
                    "nodeContext": "repoRecord=this.records.remove(flowFile.getId())",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 10,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 82,
                        "startLineNumber": 1409,
                        "startColumnNumber": 12,
                        "endLineNumber": 1409,
                        "endColumnNumber": 94
                    },
                    "nodeContext": "final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 14,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 82,
                    "startLineNumber": 1409,
                    "startColumnNumber": 12,
                    "endLineNumber": 1409,
                    "endColumnNumber": 94
                },
                "nodeContext": "final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 14,
                "astHeight": 5
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1422,
                "startColumnNumber": 63,
                "endLineNumber": 1422,
                "endColumnNumber": 71
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 56,
                        "startLineNumber": 1422,
                        "startColumnNumber": 16,
                        "endLineNumber": 1422,
                        "endColumnNumber": 72
                    },
                    "nodeContext": "unacknowledgedFlowFiles.get(inputQueue).remove(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 57,
                        "startLineNumber": 1422,
                        "startColumnNumber": 16,
                        "endLineNumber": 1422,
                        "endColumnNumber": 73
                    },
                    "nodeContext": "unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 689,
                        "startLineNumber": 1417,
                        "startColumnNumber": 36,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 80,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 713,
                        "startLineNumber": 1417,
                        "startColumnNumber": 12,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (inputQueue != null) {\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 84,
                    "astHeight": 10
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 57,
                    "startLineNumber": 1422,
                    "startColumnNumber": 16,
                    "endLineNumber": 1422,
                    "endColumnNumber": 73
                },
                "nodeContext": "unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1426,
                "startColumnNumber": 33,
                "endLineNumber": 1426,
                "endColumnNumber": 41
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1426,
                        "startColumnNumber": 33,
                        "endLineNumber": 1426,
                        "endColumnNumber": 51
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 35,
                        "startLineNumber": 1426,
                        "startColumnNumber": 16,
                        "endLineNumber": 1426,
                        "endColumnNumber": 51
                    },
                    "nodeContext": "contentSizeIn-=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 5,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 36,
                        "startLineNumber": 1426,
                        "startColumnNumber": 16,
                        "endLineNumber": 1426,
                        "endColumnNumber": 52
                    },
                    "nodeContext": "contentSizeIn-=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 6,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 689,
                        "startLineNumber": 1417,
                        "startColumnNumber": 36,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 80,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 713,
                        "startLineNumber": 1417,
                        "startColumnNumber": 12,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (inputQueue != null) {\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 84,
                    "astHeight": 10
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 36,
                    "startLineNumber": 1426,
                    "startColumnNumber": 16,
                    "endLineNumber": 1426,
                    "endColumnNumber": 52
                },
                "nodeContext": "contentSizeIn-=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 6,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1429,
                "startColumnNumber": 42,
                "endLineNumber": 1429,
                "endColumnNumber": 50
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1429,
                        "startColumnNumber": 42,
                        "endLineNumber": 1429,
                        "endColumnNumber": 60
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 44,
                        "startLineNumber": 1429,
                        "startColumnNumber": 16,
                        "endLineNumber": 1429,
                        "endColumnNumber": 60
                    },
                    "nodeContext": "newOwner.contentSizeIn+=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 45,
                        "startLineNumber": 1429,
                        "startColumnNumber": 16,
                        "endLineNumber": 1429,
                        "endColumnNumber": 61
                    },
                    "nodeContext": "newOwner.contentSizeIn+=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 689,
                        "startLineNumber": 1417,
                        "startColumnNumber": 36,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 80,
                    "astHeight": 9
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 713,
                        "startLineNumber": 1417,
                        "startColumnNumber": 12,
                        "endLineNumber": 1430,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (inputQueue != null) {\n  final String connectionId=inputQueue.getIdentifier();\n  incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n  newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n  unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n  newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n  flowFilesIn--;\n  contentSizeIn-=flowFile.getSize();\n  newOwner.flowFilesIn++;\n  newOwner.contentSizeIn+=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 84,
                    "astHeight": 10
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 45,
                    "startLineNumber": 1429,
                    "startColumnNumber": 16,
                    "endLineNumber": 1429,
                    "endColumnNumber": 61
                },
                "nodeContext": "newOwner.contentSizeIn+=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1432,
                "startColumnNumber": 38,
                "endLineNumber": 1432,
                "endColumnNumber": 46
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 48,
                        "startLineNumber": 1432,
                        "startColumnNumber": 38,
                        "endLineNumber": 1432,
                        "endColumnNumber": 86
                    },
                    "nodeContext": "flowFile.getAttribute(CoreAttributes.UUID.key())",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 61,
                        "startLineNumber": 1432,
                        "startColumnNumber": 25,
                        "endLineNumber": 1432,
                        "endColumnNumber": 86
                    },
                    "nodeContext": "flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key())",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 10,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 75,
                        "startLineNumber": 1432,
                        "startColumnNumber": 12,
                        "endLineNumber": 1432,
                        "endColumnNumber": 87
                    },
                    "nodeContext": "final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 14,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 75,
                    "startLineNumber": 1432,
                    "startColumnNumber": 12,
                    "endLineNumber": 1432,
                    "endColumnNumber": 87
                },
                "nodeContext": "final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 14,
                "astHeight": 6
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1436,
                "startColumnNumber": 41,
                "endLineNumber": 1436,
                "endColumnNumber": 49
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1436,
                        "startColumnNumber": 41,
                        "endLineNumber": 1436,
                        "endColumnNumber": 59
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 43,
                        "startLineNumber": 1436,
                        "startColumnNumber": 16,
                        "endLineNumber": 1436,
                        "endColumnNumber": 59
                    },
                    "nodeContext": "newOwner.removedBytes+=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 44,
                        "startLineNumber": 1436,
                        "startColumnNumber": 16,
                        "endLineNumber": 1436,
                        "endColumnNumber": 60
                    },
                    "nodeContext": "newOwner.removedBytes+=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 261,
                        "startLineNumber": 1433,
                        "startColumnNumber": 53,
                        "endLineNumber": 1440,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  newOwner.removedFlowFiles.add(flowFileId);\n  newOwner.removedCount++;\n  newOwner.removedBytes+=flowFile.getSize();\n  removedCount--;\n  removedBytes-=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 30,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 302,
                        "startLineNumber": 1433,
                        "startColumnNumber": 12,
                        "endLineNumber": 1440,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (removedFlowFiles.remove(flowFileId)) {\n  newOwner.removedFlowFiles.add(flowFileId);\n  newOwner.removedCount++;\n  newOwner.removedBytes+=flowFile.getSize();\n  removedCount--;\n  removedBytes-=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 35,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 44,
                    "startLineNumber": 1436,
                    "startColumnNumber": 16,
                    "endLineNumber": 1436,
                    "endColumnNumber": 60
                },
                "nodeContext": "newOwner.removedBytes+=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1439,
                "startColumnNumber": 32,
                "endLineNumber": 1439,
                "endColumnNumber": 40
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1439,
                        "startColumnNumber": 32,
                        "endLineNumber": 1439,
                        "endColumnNumber": 50
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 34,
                        "startLineNumber": 1439,
                        "startColumnNumber": 16,
                        "endLineNumber": 1439,
                        "endColumnNumber": 50
                    },
                    "nodeContext": "removedBytes-=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 5,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 35,
                        "startLineNumber": 1439,
                        "startColumnNumber": 16,
                        "endLineNumber": 1439,
                        "endColumnNumber": 51
                    },
                    "nodeContext": "removedBytes-=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 6,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 261,
                        "startLineNumber": 1433,
                        "startColumnNumber": 53,
                        "endLineNumber": 1440,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  newOwner.removedFlowFiles.add(flowFileId);\n  newOwner.removedCount++;\n  newOwner.removedBytes+=flowFile.getSize();\n  removedCount--;\n  removedBytes-=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 30,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 302,
                        "startLineNumber": 1433,
                        "startColumnNumber": 12,
                        "endLineNumber": 1440,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (removedFlowFiles.remove(flowFileId)) {\n  newOwner.removedFlowFiles.add(flowFileId);\n  newOwner.removedCount++;\n  newOwner.removedBytes+=flowFile.getSize();\n  removedCount--;\n  removedBytes-=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 35,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 35,
                    "startLineNumber": 1439,
                    "startColumnNumber": 16,
                    "endLineNumber": 1439,
                    "endColumnNumber": 51
                },
                "nodeContext": "removedBytes-=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 6,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1448,
                "startColumnNumber": 34,
                "endLineNumber": 1448,
                "endColumnNumber": 42
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1448,
                        "startColumnNumber": 34,
                        "endLineNumber": 1448,
                        "endColumnNumber": 52
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 36,
                        "startLineNumber": 1448,
                        "startColumnNumber": 16,
                        "endLineNumber": 1448,
                        "endColumnNumber": 52
                    },
                    "nodeContext": "contentSizeOut-=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 5,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 37,
                        "startLineNumber": 1448,
                        "startColumnNumber": 16,
                        "endLineNumber": 1448,
                        "endColumnNumber": 53
                    },
                    "nodeContext": "contentSizeOut-=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 6,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 206,
                        "startLineNumber": 1446,
                        "startColumnNumber": 62,
                        "endLineNumber": 1452,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  flowFilesOut--;\n  contentSizeOut-=flowFile.getSize();\n  newOwner.flowFilesOut++;\n  newOwner.contentSizeOut+=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 23,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 256,
                        "startLineNumber": 1446,
                        "startColumnNumber": 12,
                        "endLineNumber": 1452,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (repoRecord.getTransferRelationship() != null) {\n  flowFilesOut--;\n  contentSizeOut-=flowFile.getSize();\n  newOwner.flowFilesOut++;\n  newOwner.contentSizeOut+=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 29,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 37,
                    "startLineNumber": 1448,
                    "startColumnNumber": 16,
                    "endLineNumber": 1448,
                    "endColumnNumber": 53
                },
                "nodeContext": "contentSizeOut-=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 6,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1451,
                "startColumnNumber": 43,
                "endLineNumber": 1451,
                "endColumnNumber": 51
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.Assignment,rightHandSide]",
                    "nodePosition": {
                        "charLength": 18,
                        "startLineNumber": 1451,
                        "startColumnNumber": 43,
                        "endLineNumber": 1451,
                        "endColumnNumber": 61
                    },
                    "nodeContext": "flowFile.getSize()",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 3,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 45,
                        "startLineNumber": 1451,
                        "startColumnNumber": 16,
                        "endLineNumber": 1451,
                        "endColumnNumber": 61
                    },
                    "nodeContext": "newOwner.contentSizeOut+=flowFile.getSize()",
                    "nodeType": "Assignment",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 46,
                        "startLineNumber": 1451,
                        "startColumnNumber": 16,
                        "endLineNumber": 1451,
                        "endColumnNumber": 62
                    },
                    "nodeContext": "newOwner.contentSizeOut+=flowFile.getSize();\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 206,
                        "startLineNumber": 1446,
                        "startColumnNumber": 62,
                        "endLineNumber": 1452,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  flowFilesOut--;\n  contentSizeOut-=flowFile.getSize();\n  newOwner.flowFilesOut++;\n  newOwner.contentSizeOut+=flowFile.getSize();\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 23,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 256,
                        "startLineNumber": 1446,
                        "startColumnNumber": 12,
                        "endLineNumber": 1452,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (repoRecord.getTransferRelationship() != null) {\n  flowFilesOut--;\n  contentSizeOut-=flowFile.getSize();\n  newOwner.flowFilesOut++;\n  newOwner.contentSizeOut+=flowFile.getSize();\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 29,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 46,
                    "startLineNumber": 1451,
                    "startColumnNumber": 16,
                    "endLineNumber": 1451,
                    "endColumnNumber": 62
                },
                "nodeContext": "newOwner.contentSizeOut+=flowFile.getSize();\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1454,
                "startColumnNumber": 88,
                "endLineNumber": 1454,
                "endColumnNumber": 96
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 42,
                        "startLineNumber": 1454,
                        "startColumnNumber": 55,
                        "endLineNumber": 1454,
                        "endColumnNumber": 97
                    },
                    "nodeContext": "generatedProvenanceEvents.remove(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 51,
                        "startLineNumber": 1454,
                        "startColumnNumber": 46,
                        "endLineNumber": 1454,
                        "endColumnNumber": 97
                    },
                    "nodeContext": "events=generatedProvenanceEvents.remove(flowFile)",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 6,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 86,
                        "startLineNumber": 1454,
                        "startColumnNumber": 12,
                        "endLineNumber": 1454,
                        "endColumnNumber": 98
                    },
                    "nodeContext": "final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 13,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 86,
                    "startLineNumber": 1454,
                    "startColumnNumber": 12,
                    "endLineNumber": 1454,
                    "endColumnNumber": 98
                },
                "nodeContext": "final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 13,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1456,
                "startColumnNumber": 55,
                "endLineNumber": 1456,
                "endColumnNumber": 63
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 56,
                        "startLineNumber": 1456,
                        "startColumnNumber": 16,
                        "endLineNumber": 1456,
                        "endColumnNumber": 72
                    },
                    "nodeContext": "newOwner.generatedProvenanceEvents.put(flowFile,events)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 57,
                        "startLineNumber": 1456,
                        "startColumnNumber": 16,
                        "endLineNumber": 1456,
                        "endColumnNumber": 73
                    },
                    "nodeContext": "newOwner.generatedProvenanceEvents.put(flowFile,events);\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 89,
                        "startLineNumber": 1455,
                        "startColumnNumber": 32,
                        "endLineNumber": 1457,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  newOwner.generatedProvenanceEvents.put(flowFile,events);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 9,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 109,
                        "startLineNumber": 1455,
                        "startColumnNumber": 12,
                        "endLineNumber": 1457,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (events != null) {\n  newOwner.generatedProvenanceEvents.put(flowFile,events);\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 57,
                    "startLineNumber": 1456,
                    "startColumnNumber": 16,
                    "endLineNumber": 1456,
                    "endColumnNumber": 73
                },
                "nodeContext": "newOwner.generatedProvenanceEvents.put(flowFile,events);\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1467,
                "startColumnNumber": 56,
                "endLineNumber": 1467,
                "endColumnNumber": 64
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
                    "nodePosition": {
                        "charLength": 31,
                        "startLineNumber": 1467,
                        "startColumnNumber": 34,
                        "endLineNumber": 1467,
                        "endColumnNumber": 65
                    },
                    "nodeContext": "deleteOnCommit.remove(flowFile)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 4,
                    "astHeight": 2
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
                    "nodePosition": {
                        "charLength": 42,
                        "startLineNumber": 1467,
                        "startColumnNumber": 23,
                        "endLineNumber": 1467,
                        "endColumnNumber": 65
                    },
                    "nodeContext": "toDelete=deleteOnCommit.remove(flowFile)",
                    "nodeType": "VariableDeclarationFragment",
                    "astNodeNumber": 6,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 54,
                        "startLineNumber": 1467,
                        "startColumnNumber": 12,
                        "endLineNumber": 1467,
                        "endColumnNumber": 66
                    },
                    "nodeContext": "final Path toDelete=deleteOnCommit.remove(flowFile);\n",
                    "nodeType": "VariableDeclarationStatement",
                    "astNodeNumber": 10,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 54,
                    "startLineNumber": 1467,
                    "startColumnNumber": 12,
                    "endLineNumber": 1467,
                    "endColumnNumber": 66
                },
                "nodeContext": "final Path toDelete=deleteOnCommit.remove(flowFile);\n",
                "nodeType": "VariableDeclarationStatement",
                "astNodeNumber": 10,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        },
        {
            "nodeContext": "flowFile",
            "nodeType": "SimpleName",
            "nodePosition": {
                "charLength": 8,
                "startLineNumber": 1469,
                "startColumnNumber": 44,
                "endLineNumber": 1469,
                "endColumnNumber": 52
            },
            "astNodeNumber": 1,
            "astHeight": 1,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
                    "nodePosition": {
                        "charLength": 47,
                        "startLineNumber": 1469,
                        "startColumnNumber": 16,
                        "endLineNumber": 1469,
                        "endColumnNumber": 63
                    },
                    "nodeContext": "newOwner.deleteOnCommit.put(flowFile,toDelete)",
                    "nodeType": "MethodInvocation",
                    "astNodeNumber": 7,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 48,
                        "startLineNumber": 1469,
                        "startColumnNumber": 16,
                        "endLineNumber": 1469,
                        "endColumnNumber": 64
                    },
                    "nodeContext": "newOwner.deleteOnCommit.put(flowFile,toDelete);\n",
                    "nodeType": "ExpressionStatement",
                    "astNodeNumber": 8,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.IfStatement,thenStatement]",
                    "nodePosition": {
                        "charLength": 80,
                        "startLineNumber": 1468,
                        "startColumnNumber": 34,
                        "endLineNumber": 1470,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "{\n  newOwner.deleteOnCommit.put(flowFile,toDelete);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 9,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 102,
                        "startLineNumber": 1468,
                        "startColumnNumber": 12,
                        "endLineNumber": 1470,
                        "endColumnNumber": 13
                    },
                    "nodeContext": "if (toDelete != null) {\n  newOwner.deleteOnCommit.put(flowFile,toDelete);\n}\n",
                    "nodeType": "IfStatement",
                    "astNodeNumber": 13,
                    "astHeight": 6
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,body]",
                    "nodePosition": {
                        "charLength": 2999,
                        "startLineNumber": 1406,
                        "startColumnNumber": 50,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "{\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 305,
                    "astHeight": 11
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 3041,
                        "startLineNumber": 1406,
                        "startColumnNumber": 8,
                        "endLineNumber": 1471,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final FlowFile flowFile : flowFiles) {\n  final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n  final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n  newOwner.records.put(flowFileRecord.getId(),repoRecord);\n  final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n  if (inputQueue != null) {\n    final String connectionId=inputQueue.getIdentifier();\n    incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n    newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n    unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n    newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n    flowFilesIn--;\n    contentSizeIn-=flowFile.getSize();\n    newOwner.flowFilesIn++;\n    newOwner.contentSizeIn+=flowFile.getSize();\n  }\n  final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n  if (removedFlowFiles.remove(flowFileId)) {\n    newOwner.removedFlowFiles.add(flowFileId);\n    newOwner.removedCount++;\n    newOwner.removedBytes+=flowFile.getSize();\n    removedCount--;\n    removedBytes-=flowFile.getSize();\n  }\n  if (createdFlowFiles.remove(flowFileId)) {\n    newOwner.createdFlowFiles.add(flowFileId);\n  }\n  if (repoRecord.getTransferRelationship() != null) {\n    flowFilesOut--;\n    contentSizeOut-=flowFile.getSize();\n    newOwner.flowFilesOut++;\n    newOwner.contentSizeOut+=flowFile.getSize();\n  }\n  final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n  if (events != null) {\n    newOwner.generatedProvenanceEvents.put(flowFile,events);\n  }\n  final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n  if (currentClaim != null) {\n    final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n    if (appendableStream != null) {\n      newOwner.appendableStreams.put(currentClaim,appendableStream);\n    }\n  }\n  final Path toDelete=deleteOnCommit.remove(flowFile);\n  if (toDelete != null) {\n    newOwner.deleteOnCommit.put(flowFile,toDelete);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 312,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                "nodePosition": {
                    "charLength": 48,
                    "startLineNumber": 1469,
                    "startColumnNumber": 16,
                    "endLineNumber": 1469,
                    "endColumnNumber": 64
                },
                "nodeContext": "newOwner.deleteOnCommit.put(flowFile,toDelete);\n",
                "nodeType": "ExpressionStatement",
                "astNodeNumber": 8,
                "astHeight": 4
            },
            "tokenLength": 1,
            "type": "org.apache.nifi.flowfile.FlowFile"
        }
    ],
    "positionList": [
        {
            "charLength": 8,
            "startLineNumber": 1316,
            "startColumnNumber": 45,
            "endLineNumber": 1316,
            "endColumnNumber": 53
        },
        {
            "charLength": 8,
            "startLineNumber": 1317,
            "startColumnNumber": 48,
            "endLineNumber": 1317,
            "endColumnNumber": 56
        },
        {
            "charLength": 8,
            "startLineNumber": 1321,
            "startColumnNumber": 46,
            "endLineNumber": 1321,
            "endColumnNumber": 54
        },
        {
            "charLength": 8,
            "startLineNumber": 1322,
            "startColumnNumber": 48,
            "endLineNumber": 1322,
            "endColumnNumber": 56
        },
        {
            "charLength": 8,
            "startLineNumber": 1326,
            "startColumnNumber": 45,
            "endLineNumber": 1326,
            "endColumnNumber": 53
        },
        {
            "charLength": 8,
            "startLineNumber": 1327,
            "startColumnNumber": 48,
            "endLineNumber": 1327,
            "endColumnNumber": 56
        },
        {
            "charLength": 8,
            "startLineNumber": 1329,
            "startColumnNumber": 43,
            "endLineNumber": 1329,
            "endColumnNumber": 51
        },
        {
            "charLength": 8,
            "startLineNumber": 1330,
            "startColumnNumber": 48,
            "endLineNumber": 1330,
            "endColumnNumber": 56
        },
        {
            "charLength": 8,
            "startLineNumber": 1333,
            "startColumnNumber": 62,
            "endLineNumber": 1333,
            "endColumnNumber": 70
        },
        {
            "charLength": 8,
            "startLineNumber": 1335,
            "startColumnNumber": 52,
            "endLineNumber": 1335,
            "endColumnNumber": 60
        },
        {
            "charLength": 8,
            "startLineNumber": 1384,
            "startColumnNumber": 42,
            "endLineNumber": 1384,
            "endColumnNumber": 50
        },
        {
            "charLength": 8,
            "startLineNumber": 1386,
            "startColumnNumber": 53,
            "endLineNumber": 1386,
            "endColumnNumber": 61
        },
        {
            "charLength": 8,
            "startLineNumber": 1407,
            "startColumnNumber": 67,
            "endLineNumber": 1407,
            "endColumnNumber": 75
        },
        {
            "charLength": 8,
            "startLineNumber": 1409,
            "startColumnNumber": 76,
            "endLineNumber": 1409,
            "endColumnNumber": 84
        },
        {
            "charLength": 8,
            "startLineNumber": 1422,
            "startColumnNumber": 63,
            "endLineNumber": 1422,
            "endColumnNumber": 71
        },
        {
            "charLength": 8,
            "startLineNumber": 1426,
            "startColumnNumber": 33,
            "endLineNumber": 1426,
            "endColumnNumber": 41
        },
        {
            "charLength": 8,
            "startLineNumber": 1429,
            "startColumnNumber": 42,
            "endLineNumber": 1429,
            "endColumnNumber": 50
        },
        {
            "charLength": 8,
            "startLineNumber": 1432,
            "startColumnNumber": 38,
            "endLineNumber": 1432,
            "endColumnNumber": 46
        },
        {
            "charLength": 8,
            "startLineNumber": 1436,
            "startColumnNumber": 41,
            "endLineNumber": 1436,
            "endColumnNumber": 49
        },
        {
            "charLength": 8,
            "startLineNumber": 1439,
            "startColumnNumber": 32,
            "endLineNumber": 1439,
            "endColumnNumber": 40
        },
        {
            "charLength": 8,
            "startLineNumber": 1448,
            "startColumnNumber": 34,
            "endLineNumber": 1448,
            "endColumnNumber": 42
        },
        {
            "charLength": 8,
            "startLineNumber": 1451,
            "startColumnNumber": 43,
            "endLineNumber": 1451,
            "endColumnNumber": 51
        },
        {
            "charLength": 8,
            "startLineNumber": 1454,
            "startColumnNumber": 88,
            "endLineNumber": 1454,
            "endColumnNumber": 96
        },
        {
            "charLength": 8,
            "startLineNumber": 1456,
            "startColumnNumber": 55,
            "endLineNumber": 1456,
            "endColumnNumber": 63
        },
        {
            "charLength": 8,
            "startLineNumber": 1467,
            "startColumnNumber": 56,
            "endLineNumber": 1467,
            "endColumnNumber": 64
        },
        {
            "charLength": 8,
            "startLineNumber": 1469,
            "startColumnNumber": 44,
            "endLineNumber": 1469,
            "endColumnNumber": 52
        }
    ],
    "layoutRelationDataList": [
        {
            "firstKey": 0,
            "secondKey": 1,
            "layout": 1
        },
        {
            "firstKey": 0,
            "secondKey": 2,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 3,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 4,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 5,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 6,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 7,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 8,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 9,
            "layout": 2
        },
        {
            "firstKey": 0,
            "secondKey": 10,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 11,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 0,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 1,
            "secondKey": 0,
            "layout": 4
        },
        {
            "firstKey": 1,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 1,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 1,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 2,
            "secondKey": 0,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 1,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 3,
            "layout": 1
        },
        {
            "firstKey": 2,
            "secondKey": 4,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 5,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 6,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 7,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 8,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 9,
            "layout": 2
        },
        {
            "firstKey": 2,
            "secondKey": 10,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 11,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 2,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 3,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 2,
            "layout": 4
        },
        {
            "firstKey": 3,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 3,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 3,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 4,
            "secondKey": 0,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 1,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 2,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 3,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 5,
            "layout": 1
        },
        {
            "firstKey": 4,
            "secondKey": 6,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 7,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 8,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 9,
            "layout": 2
        },
        {
            "firstKey": 4,
            "secondKey": 10,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 11,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 4,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 5,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 4,
            "layout": 4
        },
        {
            "firstKey": 5,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 5,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 5,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 6,
            "secondKey": 0,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 1,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 2,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 3,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 4,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 5,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 7,
            "layout": 1
        },
        {
            "firstKey": 6,
            "secondKey": 8,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 9,
            "layout": 2
        },
        {
            "firstKey": 6,
            "secondKey": 10,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 11,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 6,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 7,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 6,
            "layout": 4
        },
        {
            "firstKey": 7,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 7,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 7,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 8,
            "secondKey": 0,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 1,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 2,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 3,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 4,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 5,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 6,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 7,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 9,
            "layout": 3
        },
        {
            "firstKey": 8,
            "secondKey": 10,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 11,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 14,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 15,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 16,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 18,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 19,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 20,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 21,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 8,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 9,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 9,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 11,
            "layout": 3
        },
        {
            "firstKey": 10,
            "secondKey": 12,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 13,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 14,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 15,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 16,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 17,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 18,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 19,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 20,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 21,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 22,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 23,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 24,
            "layout": 7
        },
        {
            "firstKey": 10,
            "secondKey": 25,
            "layout": 7
        },
        {
            "firstKey": 11,
            "secondKey": 0,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 1,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 2,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 3,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 4,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 5,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 6,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 7,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 8,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 9,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 10,
            "layout": 4
        },
        {
            "firstKey": 11,
            "secondKey": 12,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 13,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 14,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 15,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 16,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 17,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 18,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 19,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 20,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 21,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 22,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 23,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 24,
            "layout": 8
        },
        {
            "firstKey": 11,
            "secondKey": 25,
            "layout": 8
        },
        {
            "firstKey": 12,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 10,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 11,
            "layout": 5
        },
        {
            "firstKey": 12,
            "secondKey": 13,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 15,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 16,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 17,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 18,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 19,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 20,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 21,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 22,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 23,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 24,
            "layout": 3
        },
        {
            "firstKey": 12,
            "secondKey": 25,
            "layout": 3
        },
        {
            "firstKey": 13,
            "secondKey": 0,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 1,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 2,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 3,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 4,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 5,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 6,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 7,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 8,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 9,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 10,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 11,
            "layout": 6
        },
        {
            "firstKey": 13,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 13,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 0,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 1,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 2,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 3,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 4,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 5,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 6,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 7,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 8,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 9,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 10,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 11,
            "layout": 6
        },
        {
            "firstKey": 14,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 15,
            "layout": 2
        },
        {
            "firstKey": 14,
            "secondKey": 16,
            "layout": 2
        },
        {
            "firstKey": 14,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 14,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 15,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 15,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 15,
            "secondKey": 16,
            "layout": 3
        },
        {
            "firstKey": 15,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 18,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 19,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 20,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 21,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 15,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 16,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 16,
            "secondKey": 15,
            "layout": 3
        },
        {
            "firstKey": 16,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 18,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 19,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 20,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 21,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 16,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 10,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 11,
            "layout": 5
        },
        {
            "firstKey": 17,
            "secondKey": 12,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 13,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 15,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 16,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 18,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 19,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 20,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 21,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 22,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 23,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 24,
            "layout": 3
        },
        {
            "firstKey": 17,
            "secondKey": 25,
            "layout": 3
        },
        {
            "firstKey": 18,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 18,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 14,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 15,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 16,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 19,
            "layout": 3
        },
        {
            "firstKey": 18,
            "secondKey": 20,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 21,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 18,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 19,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 14,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 15,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 16,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 18,
            "layout": 3
        },
        {
            "firstKey": 19,
            "secondKey": 20,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 21,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 19,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 20,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 14,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 15,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 16,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 18,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 19,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 21,
            "layout": 3
        },
        {
            "firstKey": 20,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 20,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 0,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 1,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 2,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 3,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 4,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 5,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 6,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 7,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 8,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 9,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 10,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 11,
            "layout": 7
        },
        {
            "firstKey": 21,
            "secondKey": 12,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 13,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 14,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 15,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 16,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 17,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 18,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 19,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 20,
            "layout": 3
        },
        {
            "firstKey": 21,
            "secondKey": 22,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 23,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 24,
            "layout": 5
        },
        {
            "firstKey": 21,
            "secondKey": 25,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 10,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 11,
            "layout": 5
        },
        {
            "firstKey": 22,
            "secondKey": 12,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 13,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 15,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 16,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 17,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 18,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 19,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 20,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 21,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 23,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 24,
            "layout": 3
        },
        {
            "firstKey": 22,
            "secondKey": 25,
            "layout": 3
        },
        {
            "firstKey": 23,
            "secondKey": 0,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 1,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 2,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 3,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 4,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 5,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 6,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 7,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 8,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 9,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 10,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 11,
            "layout": 6
        },
        {
            "firstKey": 23,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 24,
            "layout": 4
        },
        {
            "firstKey": 23,
            "secondKey": 25,
            "layout": 4
        },
        {
            "firstKey": 24,
            "secondKey": 0,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 1,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 2,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 3,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 4,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 5,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 6,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 7,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 8,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 9,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 10,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 11,
            "layout": 5
        },
        {
            "firstKey": 24,
            "secondKey": 12,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 13,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 14,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 15,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 16,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 17,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 18,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 19,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 20,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 21,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 22,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 23,
            "layout": 3
        },
        {
            "firstKey": 24,
            "secondKey": 25,
            "layout": 3
        },
        {
            "firstKey": 25,
            "secondKey": 0,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 1,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 2,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 3,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 4,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 5,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 6,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 7,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 8,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 9,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 10,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 11,
            "layout": 6
        },
        {
            "firstKey": 25,
            "secondKey": 12,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 13,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 14,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 15,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 16,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 17,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 18,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 19,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 20,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 21,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 22,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 23,
            "layout": 4
        },
        {
            "firstKey": 25,
            "secondKey": 24,
            "layout": 4
        }
    ]
}