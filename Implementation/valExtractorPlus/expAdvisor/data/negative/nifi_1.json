{
    "id": 1,
    "expression": "Map.Entry",
    "projectName": "nifi",
    "commitID": "84b2484fd46a0fc883e8b9d380ccef199432db35",
    "filePath": "nifi-nar-bundles/nifi-framework-bundle/nifi-framework/nifi-framework-components/src/main/java/org/apache/nifi/controller/repository/StandardProcessSession.java",
    "occurrences": 2,
    "isArithmeticExpression": 0,
    "isGetTypeMethod": 0,
    "expressionList": [
        {
            "nodeContext": "Map.Entry",
            "nodeType": "QualifiedName",
            "nodePosition": {
                "charLength": 9,
                "startLineNumber": 1347,
                "startColumnNumber": 19,
                "endLineNumber": 1347,
                "endColumnNumber": 28
            },
            "astNodeNumber": 3,
            "astHeight": 2,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ParameterizedType,type]",
                    "nodePosition": {
                        "charLength": 9,
                        "startLineNumber": 1347,
                        "startColumnNumber": 19,
                        "endLineNumber": 1347,
                        "endColumnNumber": 28
                    },
                    "nodeContext": "Map.Entry",
                    "nodeType": "SimpleType",
                    "astNodeNumber": 4,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.SingleVariableDeclaration,type]",
                    "nodePosition": {
                        "charLength": 43,
                        "startLineNumber": 1347,
                        "startColumnNumber": 19,
                        "endLineNumber": 1347,
                        "endColumnNumber": 62
                    },
                    "nodeContext": "Map.Entry<FlowFile,ProvenanceEventBuilder>",
                    "nodeType": "ParameterizedType",
                    "astNodeNumber": 9,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,parameter]",
                    "nodePosition": {
                        "charLength": 55,
                        "startLineNumber": 1347,
                        "startColumnNumber": 13,
                        "endLineNumber": 1347,
                        "endColumnNumber": 68
                    },
                    "nodeContext": "final Map.Entry<FlowFile,ProvenanceEventBuilder> entry",
                    "nodeType": "SingleVariableDeclaration",
                    "astNodeNumber": 12,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1478,
                        "startLineNumber": 1347,
                        "startColumnNumber": 8,
                        "endLineNumber": 1366,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n  final FlowFile eventFlowFile=entry.getKey();\n  if (flowFiles.contains(eventFlowFile)) {\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    for (    final String childId : eventBuilder.getChildFlowFileIds()) {\n      if (!flowFileIds.contains(childId)) {\n        throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n      }\n    }\n  }\n else {\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    for (    final String childId : eventBuilder.getChildFlowFileIds()) {\n      if (flowFileIds.contains(childId)) {\n        throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n      }\n    }\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 107,
                    "astHeight": 14
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,parameter]",
                "nodePosition": {
                    "charLength": 55,
                    "startLineNumber": 1347,
                    "startColumnNumber": 13,
                    "endLineNumber": 1347,
                    "endColumnNumber": 68
                },
                "nodeContext": "final Map.Entry<FlowFile,ProvenanceEventBuilder> entry",
                "nodeType": "SingleVariableDeclaration",
                "astNodeNumber": 12,
                "astHeight": 5
            },
            "tokenLength": 2,
            "type": "java.util.Map.Entry<org.apache.nifi.flowfile.FlowFile,org.apache.nifi.provenance.ProvenanceEventBuilder>"
        },
        {
            "nodeContext": "Map.Entry",
            "nodeType": "QualifiedName",
            "nodePosition": {
                "charLength": 9,
                "startLineNumber": 1371,
                "startColumnNumber": 19,
                "endLineNumber": 1371,
                "endColumnNumber": 28
            },
            "astNodeNumber": 3,
            "astHeight": 2,
            "parentDataList": [
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.ParameterizedType,type]",
                    "nodePosition": {
                        "charLength": 9,
                        "startLineNumber": 1371,
                        "startColumnNumber": 19,
                        "endLineNumber": 1371,
                        "endColumnNumber": 28
                    },
                    "nodeContext": "Map.Entry",
                    "nodeType": "SimpleType",
                    "astNodeNumber": 4,
                    "astHeight": 3
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.SingleVariableDeclaration,type]",
                    "nodePosition": {
                        "charLength": 43,
                        "startLineNumber": 1371,
                        "startColumnNumber": 19,
                        "endLineNumber": 1371,
                        "endColumnNumber": 62
                    },
                    "nodeContext": "Map.Entry<FlowFile,ProvenanceEventBuilder>",
                    "nodeType": "ParameterizedType",
                    "astNodeNumber": 9,
                    "astHeight": 4
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,parameter]",
                    "nodePosition": {
                        "charLength": 55,
                        "startLineNumber": 1371,
                        "startColumnNumber": 13,
                        "endLineNumber": 1371,
                        "endColumnNumber": 68
                    },
                    "nodeContext": "final Map.Entry<FlowFile,ProvenanceEventBuilder> entry",
                    "nodeType": "SingleVariableDeclaration",
                    "astNodeNumber": 12,
                    "astHeight": 5
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
                    "nodePosition": {
                        "charLength": 1320,
                        "startLineNumber": 1371,
                        "startColumnNumber": 8,
                        "endLineNumber": 1400,
                        "endColumnNumber": 9
                    },
                    "nodeContext": "for (final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n  final FlowFile eventFlowFile=entry.getKey();\n  final ProvenanceEventBuilder eventBuilder=entry.getValue();\n  if (!flowFiles.contains(eventFlowFile)) {\n    continue;\n  }\n  final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n  ProvenanceEventBuilder copy=null;\n  for (  final FlowFile flowFile : flowFiles) {\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (childrenIds.contains(flowFileId)) {\n      eventBuilder.removeChildFlowFile(flowFile);\n      if (copy == null) {\n        copy=eventBuilder.copy();\n        copy.getChildFlowFileIds().clear();\n      }\n      copy.addChildFlowFile(flowFileId);\n    }\n  }\n  if (copy != null) {\n    newOwner.forkEventBuilders.put(eventFlowFile,copy);\n    forkedFlowFilesMigrated.add(eventFlowFile);\n  }\n}\n",
                    "nodeType": "EnhancedForStatement",
                    "astNodeNumber": 138,
                    "astHeight": 12
                },
                {
                    "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
                    "nodePosition": {
                        "charLength": 8791,
                        "startLineNumber": 1311,
                        "startColumnNumber": 96,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "{\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "Block",
                    "astNodeNumber": 730,
                    "astHeight": 15
                },
                {
                    "locationInParent": "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
                    "nodePosition": {
                        "charLength": 8883,
                        "startLineNumber": 1311,
                        "startColumnNumber": 4,
                        "endLineNumber": 1474,
                        "endColumnNumber": 5
                    },
                    "nodeContext": "private void migrate(final StandardProcessSession newOwner,Collection<FlowFile> flowFiles){\n  flowFiles=flowFiles.stream().map(this::getMostRecent).collect(Collectors.toList());\n  for (  final FlowFile flowFile : flowFiles) {\n    if (openInputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open InputStream for the FlowFile, created by calling ProcessSession.read(FlowFile)\");\n    }\n    if (openOutputStreams.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" cannot be migrated to a new Process Session because this session currently \" + \"has an open OutputStream for the FlowFile, created by calling ProcessSession.write(FlowFile)\");\n    }\n    if (readRecursionSet.containsKey(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or InputStream created by ProcessSession.read(FlowFile) has not been closed\");\n    }\n    if (writeRecursionSet.contains(flowFile)) {\n      throw new IllegalStateException(flowFile + \" already in use for an active callback or OutputStream created by ProcessSession.write(FlowFile) has not been closed\");\n    }\n    final StandardRepositoryRecord record=getRecord(flowFile);\n    if (record == null) {\n      throw new FlowFileHandlingException(flowFile + \" is not known in this session (\" + toString()+ \")\");\n    }\n  }\n  final Set<String> flowFileIds=flowFiles.stream().map(ff -> ff.getAttribute(CoreAttributes.UUID.key())).collect(Collectors.toSet());\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    if (flowFiles.contains(eventFlowFile)) {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (!flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked to create \"+ eventBuilder.getChildFlowFileIds().size()+ \" children and not all children are being migrated. If any FlowFile is forked, all of its children must also be migrated at the same time as the forked FlowFile\");\n        }\n      }\n    }\n else {\n      final ProvenanceEventBuilder eventBuilder=entry.getValue();\n      for (      final String childId : eventBuilder.getChildFlowFileIds()) {\n        if (flowFileIds.contains(childId)) {\n          throw new FlowFileHandlingException(\"Cannot migrate \" + eventFlowFile + \" to a new session because it was forked from a Parent FlowFile, but the parent is not being migrated. \"+ \"If any FlowFile is forked, the parent and all children must be migrated at the same time.\");\n        }\n      }\n    }\n  }\n  final Set<FlowFile> forkedFlowFilesMigrated=new HashSet<>();\n  for (  final Map.Entry<FlowFile,ProvenanceEventBuilder> entry : forkEventBuilders.entrySet()) {\n    final FlowFile eventFlowFile=entry.getKey();\n    final ProvenanceEventBuilder eventBuilder=entry.getValue();\n    if (!flowFiles.contains(eventFlowFile)) {\n      continue;\n    }\n    final Set<String> childrenIds=new HashSet<>(eventBuilder.getChildFlowFileIds());\n    ProvenanceEventBuilder copy=null;\n    for (    final FlowFile flowFile : flowFiles) {\n      final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n      if (childrenIds.contains(flowFileId)) {\n        eventBuilder.removeChildFlowFile(flowFile);\n        if (copy == null) {\n          copy=eventBuilder.copy();\n          copy.getChildFlowFileIds().clear();\n        }\n        copy.addChildFlowFile(flowFileId);\n      }\n    }\n    if (copy != null) {\n      newOwner.forkEventBuilders.put(eventFlowFile,copy);\n      forkedFlowFilesMigrated.add(eventFlowFile);\n    }\n  }\n  forkedFlowFilesMigrated.forEach(forkEventBuilders::remove);\n  newOwner.processingStartTime=Math.min(newOwner.processingStartTime,processingStartTime);\n  for (  final FlowFile flowFile : flowFiles) {\n    final FlowFileRecord flowFileRecord=(FlowFileRecord)flowFile;\n    final StandardRepositoryRecord repoRecord=this.records.remove(flowFile.getId());\n    newOwner.records.put(flowFileRecord.getId(),repoRecord);\n    final FlowFileQueue inputQueue=repoRecord.getOriginalQueue();\n    if (inputQueue != null) {\n      final String connectionId=inputQueue.getIdentifier();\n      incrementConnectionOutputCounts(connectionId,-1,-repoRecord.getOriginal().getSize());\n      newOwner.incrementConnectionOutputCounts(connectionId,1,repoRecord.getOriginal().getSize());\n      unacknowledgedFlowFiles.get(inputQueue).remove(flowFile);\n      newOwner.unacknowledgedFlowFiles.computeIfAbsent(inputQueue,queue -> new HashSet<>()).add(flowFileRecord);\n      flowFilesIn--;\n      contentSizeIn-=flowFile.getSize();\n      newOwner.flowFilesIn++;\n      newOwner.contentSizeIn+=flowFile.getSize();\n    }\n    final String flowFileId=flowFile.getAttribute(CoreAttributes.UUID.key());\n    if (removedFlowFiles.remove(flowFileId)) {\n      newOwner.removedFlowFiles.add(flowFileId);\n      newOwner.removedCount++;\n      newOwner.removedBytes+=flowFile.getSize();\n      removedCount--;\n      removedBytes-=flowFile.getSize();\n    }\n    if (createdFlowFiles.remove(flowFileId)) {\n      newOwner.createdFlowFiles.add(flowFileId);\n    }\n    if (repoRecord.getTransferRelationship() != null) {\n      flowFilesOut--;\n      contentSizeOut-=flowFile.getSize();\n      newOwner.flowFilesOut++;\n      newOwner.contentSizeOut+=flowFile.getSize();\n    }\n    final List<ProvenanceEventRecord> events=generatedProvenanceEvents.remove(flowFile);\n    if (events != null) {\n      newOwner.generatedProvenanceEvents.put(flowFile,events);\n    }\n    final ContentClaim currentClaim=repoRecord.getCurrentClaim();\n    if (currentClaim != null) {\n      final ByteCountingOutputStream appendableStream=appendableStreams.remove(currentClaim);\n      if (appendableStream != null) {\n        newOwner.appendableStreams.put(currentClaim,appendableStream);\n      }\n    }\n    final Path toDelete=deleteOnCommit.remove(flowFile);\n    if (toDelete != null) {\n      newOwner.deleteOnCommit.put(flowFile,toDelete);\n    }\n  }\n  provenanceReporter.migrate(newOwner.provenanceReporter,flowFileIds);\n}\n",
                    "nodeType": "MethodDeclaration",
                    "astNodeNumber": 746,
                    "astHeight": 16
                }
            ],
            "currentLineData": {
                "locationInParent": "ChildProperty[org.eclipse.jdt.core.dom.EnhancedForStatement,parameter]",
                "nodePosition": {
                    "charLength": 55,
                    "startLineNumber": 1371,
                    "startColumnNumber": 13,
                    "endLineNumber": 1371,
                    "endColumnNumber": 68
                },
                "nodeContext": "final Map.Entry<FlowFile,ProvenanceEventBuilder> entry",
                "nodeType": "SingleVariableDeclaration",
                "astNodeNumber": 12,
                "astHeight": 5
            },
            "tokenLength": 2,
            "type": "java.util.Map.Entry<org.apache.nifi.flowfile.FlowFile,org.apache.nifi.provenance.ProvenanceEventBuilder>"
        }
    ],
    "positionList": [
        {
            "charLength": 9,
            "startLineNumber": 1347,
            "startColumnNumber": 19,
            "endLineNumber": 1347,
            "endColumnNumber": 28
        },
        {
            "charLength": 9,
            "startLineNumber": 1371,
            "startColumnNumber": 19,
            "endLineNumber": 1371,
            "endColumnNumber": 28
        }
    ],
    "layoutRelationDataList": [
        {
            "firstKey": 0,
            "secondKey": 1,
            "layout": 4
        },
        {
            "firstKey": 1,
            "secondKey": 0,
            "layout": 4
        }
    ]
}